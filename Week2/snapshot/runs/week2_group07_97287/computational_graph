digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140493392704464 [label="
 (1, 11)" fillcolor=darkolivegreen1]
	140493392635424 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 150)
mat1_sym_strides:       (150, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (150, 11)
mat2_sym_strides:       (1, 150)"]
	140493392635712 -> 140493392635424
	140493392703984 [label="output_layer.bias
 (11)" fillcolor=lightblue]
	140493392703984 -> 140493392635712
	140493392635712 [label=AccumulateGrad]
	140493392635616 -> 140493392635424
	140493392635616 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140493392635568 -> 140493392635616
	140493392635568 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 300)
mat1_sym_strides:       (300, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (300, 150)
mat2_sym_strides:       (1, 300)"]
	140493392635856 -> 140493392635568
	140493392704064 [label="layer3.bias
 (150)" fillcolor=lightblue]
	140493392704064 -> 140493392635856
	140493392635856 [label=AccumulateGrad]
	140493392635808 -> 140493392635568
	140493392635808 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140493392635952 -> 140493392635808
	140493392635952 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 600)
mat1_sym_strides:       (600, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (600, 300)
mat2_sym_strides:       (1, 600)"]
	140493392636144 -> 140493392635952
	140493399690432 [label="layer2.bias
 (300)" fillcolor=lightblue]
	140493399690432 -> 140493392636144
	140493392636144 [label=AccumulateGrad]
	140493392636096 -> 140493392635952
	140493392636096 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140493392636240 -> 140493392636096
	140493392636240 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (1, 150528)
mat1_sym_strides:             ()
mat2            :           None
mat2_sym_sizes  :  (150528, 600)
mat2_sym_strides:    (1, 150528)"]
	140493392636432 -> 140493392636240
	140493400165648 [label="layer1.bias
 (600)" fillcolor=lightblue]
	140493400165648 -> 140493392636432
	140493392636432 [label=AccumulateGrad]
	140493392636384 -> 140493392636240
	140493392636384 [label=TBackward0]
	140493392636480 -> 140493392636384
	140493401806368 [label="layer1.weight
 (600, 150528)" fillcolor=lightblue]
	140493401806368 -> 140493392636480
	140493392636480 [label=AccumulateGrad]
	140493392636048 -> 140493392635952
	140493392636048 [label=TBackward0]
	140493392636528 -> 140493392636048
	140493399689072 [label="layer2.weight
 (300, 600)" fillcolor=lightblue]
	140493399689072 -> 140493392636528
	140493392636528 [label=AccumulateGrad]
	140493392635520 -> 140493392635568
	140493392635520 [label=TBackward0]
	140493392636336 -> 140493392635520
	140493400025312 [label="layer3.weight
 (150, 300)" fillcolor=lightblue]
	140493400025312 -> 140493392636336
	140493392636336 [label=AccumulateGrad]
	140493392635664 -> 140493392635424
	140493392635664 [label=TBackward0]
	140493392636192 -> 140493392635664
	140493392704384 [label="output_layer.weight
 (11, 150)" fillcolor=lightblue]
	140493392704384 -> 140493392636192
	140493392636192 [label=AccumulateGrad]
	140493392635424 -> 140493392704464
}
